{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the model in a inference behaviour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load a cv config with all experiment parameters\n",
    "2. Load the corresponding data, \n",
    "3. create a train and validation generator with the given parameters, exclusive the augmentation parameters\n",
    "4. reconstruct the model with the given parameters, (we have custom loss functions, simple model.load() will not work)\n",
    "5. load and apply the corresponding weights (with respect to the distributed training strategy)\n",
    "6. predict the targt vectors with the train and val generators (make sure that we change the batchsize to 1, and avoid shuffle so that we get all files)\n",
    "7. write the gt and predictions as numpy into the corresponding experiment folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search for root_dir and set working directory\n",
      "Working directory set to: /mnt/ssd/git/dynamic-cmr-models\n",
      "['/gpu:0', '/gpu:1']\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------define logging and working directory\n",
    "from ProjectRoot import change_wd_to_project_root\n",
    "change_wd_to_project_root()\n",
    "from src.utils.Tensorflow_helper import choose_gpu_by_id\n",
    "# ------------------------------------------define GPU id/s to use\n",
    "GPU_IDS = '0,1'\n",
    "GPUS = choose_gpu_by_id(GPU_IDS)\n",
    "print(GPUS)\n",
    "# ------------------------------------------jupyter magic config\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "# ------------------------------------------ import helpers\n",
    "# this should import glob, os, and some other standard libs to keep this cell clean\n",
    "# local imports\n",
    "from src.utils.Notebook_imports import *\n",
    "from src.utils.Utils_io import Console_and_file_logger, init_config\n",
    "\n",
    "# import external libs\n",
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ipyfilechooser import FileChooser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a config into the global namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8938b27a6c14a86989fb6099156e1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/mnt/ssd/git/dynamic-cmr-models/exp/cv_baseline', filename='', title='HTML(value='', layout=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6df6394b43e34fdbbb1cbffe74759962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Button(description='Run Interact', style=ButtonStyle()), Output()), _dom_classes=('widge…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exp_config_chooser = FileChooser(os.path.join(os.getcwd(),'exp/cv_baseline'), '')\n",
    "display(exp_config_chooser)\n",
    "@interact_manual\n",
    "def load_config():\n",
    "\n",
    "    global exp_config_chooser, config\n",
    "    \"\"\"\n",
    "    load an experiment config\n",
    "    \"\"\"\n",
    "    if 'exp_config_chooser' in globals():\n",
    "        config_file  = exp_config_chooser.selected\n",
    "    else:\n",
    "        print('no config chooser found')\n",
    "\n",
    "    # load the experiment config\n",
    "    with open(config_file, encoding='utf-8') as data_file:\n",
    "        config = json.loads(data_file.read())\n",
    "    globals().update(config)\n",
    "    Console_and_file_logger(EXPERIMENT, logging.INFO)\n",
    "    logging.info('Loaded config for experiment: {}'.format(config['EXPERIMENT']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the corresponding file names for this fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-04 07:49:34,817 INFO no files found, try to load with clean.nrrd/mask.nrrd pattern\n",
      "2021-03-04 07:49:34,825 INFO Found 278 images/masks in /mnt/ssd/data/gcn/02_imported_4D_unfiltered/SAX/\n",
      "2021-03-04 07:49:34,825 INFO Patients train: 209\n",
      "2021-03-04 07:49:34,836 INFO Selected 209 of 278 files with 209 of 279 patients for training fold 0\n",
      "2021-03-04 07:49:34,837 INFO SAX train CMR: 209, SAX train masks: 209\n",
      "2021-03-04 07:49:34,837 INFO SAX val CMR: 69, SAX val masks: 69\n"
     ]
    }
   ],
   "source": [
    "# Load SAX volumes\n",
    "from src.data.Dataset import get_trainings_files\n",
    "x_train_sax, y_train_sax, x_val_sax, y_val_sax = get_trainings_files(data_path=DATA_PATH_SAX,\n",
    "                                                                     path_to_folds_df=DF_FOLDS,\n",
    "                                                                     fold=FOLD)\n",
    "logging.info('SAX train CMR: {}, SAX train masks: {}'.format(len(x_train_sax), len(y_train_sax)))\n",
    "logging.info('SAX val CMR: {}, SAX val masks: {}'.format(len(x_val_sax), len(y_val_sax)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the same the train and val generators as used for the training of this model\n",
    "\n",
    "Make sure that:\n",
    "- no shuffle\n",
    "- no augmentation (classic and temporal)\n",
    "- batchsize equal 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-04 07:49:36,238 INFO Create DataGenerator\n",
      "2021-03-04 07:49:36,239 INFO Datagenerator created with: \n",
      " shape: [8, 64, 64]\n",
      " spacing: [8, 3, 3]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 209 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-03-04 07:49:36,239 INFO No augmentation\n",
      "2021-03-04 07:49:36,254 INFO Smoothing kernel: \n",
      "[ 1.   1.8  2.6  3.4  4.2  5.  10.   5.   4.2  3.4  2.6  1.8  1. ]\n",
      "2021-03-04 07:49:36,255 INFO Temporal phase augmentation: \n",
      "False\n",
      "Repeat volume: \n",
      "True\n",
      "2021-03-04 07:49:36,255 INFO Create DataGenerator\n",
      "2021-03-04 07:49:36,256 INFO Datagenerator created with: \n",
      " shape: [8, 64, 64]\n",
      " spacing: [8, 3, 3]\n",
      " batchsize: 1\n",
      " Scaler: MinMax\n",
      " Images: 69 \n",
      " Augment: False \n",
      " Thread workers: 8\n",
      "2021-03-04 07:49:36,256 INFO No augmentation\n",
      "2021-03-04 07:49:36,273 INFO Smoothing kernel: \n",
      "[ 1.   1.8  2.6  3.4  4.2  5.  10.   5.   4.2  3.4  2.6  1.8  1. ]\n",
      "2021-03-04 07:49:36,274 INFO Temporal phase augmentation: \n",
      "False\n",
      "Repeat volume: \n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# logging.getLogger().setLevel(logging.INFO)\n",
    "from src.data.Generators import PhaseRegressionGenerator\n",
    "config['SHUFFLE'] = False\n",
    "config['AUGMENT'] = False\n",
    "config['AUGMENT_PHASES'] = False\n",
    "config['BATCHSIZE'] = 1\n",
    "batch_generator = PhaseRegressionGenerator(x_train_sax, x_train_sax, config=config)\n",
    "# create another config for the validation data, \n",
    "# by this we can have a different set of parameters for both generators\n",
    "val_config = config.copy()\n",
    "validation_generator = PhaseRegressionGenerator(x_val_sax, x_val_sax, config=val_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model, load and set the corresponding weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-04 07:49:41,777 INFO loaded model weights as h5 file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after the temporal encoder\n",
      "(None, 36, 8, 4, 4, 512)\n",
      "Shape after GAP\n",
      "(None, 36, 512)\n",
      "Shape after Bi-LSTM layer\n",
      "(None, 36, 512)\n",
      "Shape after final conv layer\n",
      "(None, 36, 5)\n"
     ]
    }
   ],
   "source": [
    "from src.models.Models import create_PhaseRegressionModel\n",
    "# create a model\n",
    "model = create_PhaseRegressionModel(config)\n",
    "model.load_weights(os.path.join(config['MODEL_PATH'],'model.h5'))\n",
    "logging.info('loaded model weights as h5 file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on the validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-04 07:49:53,318 INFO (69, 2, 36, 5)\n"
     ]
    }
   ],
   "source": [
    "# predict on the validation generator\n",
    "preds = model.predict(validation_generator)\n",
    "logging.info(preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create one numpy object from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-04 07:50:01,642 INFO (69, 2, 36, 5)\n"
     ]
    }
   ],
   "source": [
    "# get all ground truth vectors\n",
    "gts = np.stack([np.squeeze(y) for x, y in validation_generator])\n",
    "logging.info(gts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save gt and pred into the experiment folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-04 07:51:28,850 INFO saved as: \n",
      "exp/cv_baseline/8_64_64__8_3_3_tenc64_conv1_MSE_NOnorm_augshiftscalerotdown_taug3_3_batch8_f0/2021-03-02_13_28/pred/gtpred_fold0.npy \n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "pred_path = os.path.join(config['EXP_PATH'], 'pred')\n",
    "ensure_dir(pred_path)\n",
    "pred_filename = os.path.join(pred_path, 'gtpred_fold{}.npy'.format(config['FOLD']))\n",
    "np.save(pred_filename, np.stack([gts, preds], axis=0))\n",
    "logging.info('saved as: \\n{} \\ndone!'.format(pred_filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undo the generator steps\n",
    "\n",
    "- If we have masks, undo the cropping/padding, resampling etc. so that our masks have the same size/spacing and name as our input volumes\n",
    "- If we have regression coordinates, make sure that they could be applied on the input volumes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the gts, predictions testwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dcmr",
   "language": "python",
   "name": "dcmr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
